{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get parsed data out of CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_relevant_data(parent_file_path, treatment_number):\n",
    "    '''Function which takes the relevant data out of the CSV file for a certain treatment's statistics'''\n",
    "    \n",
    "    file_path = parent_file_path + str(treatment_number) + \".csv\"\n",
    "    df = pd.read_csv(file_path) #read in as pandas data frame\n",
    "\t\n",
    "    audio_ellen = {\n",
    "\t\t'packetLoss': df['RIA_fractionLost_ellen'].tolist(),\n",
    "\t\t'bitRate': df['IT01A_bytesReceived_in_bits/s_ellen'].tolist(),\n",
    "\t\t'roundTripTime': df['RIA_roundTripTime_ellen'].tolist(),\n",
    "\t\t'bufferDelay': df['IT01A_jitterBufferDelay/emissions_ellen'].tolist(),\n",
    "\t\t'fec': df['IT01A_(dtx, fec)_ellen'].tolist(),\n",
    "\t\t'dtx': df['IT01A_(dtx, fec)_ellen'].tolist()}\n",
    "    video_ellen = {\n",
    "\t\t'packetLoss': df['RIV_fractionLost_ellen'].tolist(),\n",
    "\t\t'bitRate': df['IT01V_bytesReceived_in_bits/s_ellen'].tolist(),\n",
    "\t\t'roundTripTime': df['RIV_roundTripTime_ellen'].tolist(), \n",
    "\t\t'bufferDelay': df['IT01V_jitterBufferDelay/emissions_ellen'].tolist(),\n",
    "\t\t'codec': df['IT01V_codec_ellen'].tolist(),\n",
    "\t\t'width': df['IT01V_frameWidth_ellen'].tolist(),\n",
    "\t\t'expectedWidth': df['SV2_width_ellen'].tolist(),\n",
    "\t\t'height': df['IT01V_frameHeight_ellen'].tolist(),\n",
    "\t\t'expectedHeight': df['SV2_height_ellen'].tolist(),\n",
    "\t\t'frameRate': df['IT01V_framesPerSecond_ellen'].tolist(),\n",
    "\t\t'expectedFrameRate': df['SV2_framesPerSecond_ellen'].tolist()}\n",
    "    audio_aadya = {\n",
    "\t\t'packetLoss': df['RIA_fractionLost_aadya'].tolist(),\n",
    "\t\t'bitRate': df['IT01A_bytesReceived_in_bits/s_aadya'].tolist(),\n",
    "\t\t'roundTripTime': df['RIA_roundTripTime_aadya'].tolist(),\n",
    "\t\t'bufferDelay': df['IT01A_jitterBufferDelay/emissions_aadya'].tolist(),\n",
    "\t\t'fec': df['IT01A_(dtx, fec)_aadya'].tolist(),\n",
    "\t\t'dtx': df['IT01A_(dtx, fec)_aadya'].tolist()}\n",
    "    video_aadya = {\n",
    "\t\t'packetLoss': df['RIV_fractionLost_aadya'].tolist(),\n",
    "\t\t'bitRate': df['IT01V_bytesReceived_in_bits/s_aadya'].tolist(),\n",
    "\t\t'roundTripTime': df['RIV_roundTripTime_aadya'].tolist(), \n",
    "\t\t'bufferDelay': df['IT01V_jitterBufferDelay/emissions_aadya'].tolist(),\n",
    "\t\t'codec': df['IT01V_codec_aadya'].tolist(),\n",
    "\t\t'width': df['IT01V_frameWidth_aadya'].tolist(),\n",
    "\t\t'expectedWidth': df['SV2_width_aadya'].tolist(),\n",
    "\t\t'height': df['IT01V_frameHeight_aadya'].tolist(),\n",
    "\t\t'expectedHeight': df['SV2_height_aadya'].tolist(),\n",
    "\t\t'frameRate': df['IT01V_framesPerSecond_aadya'].tolist(),\n",
    "\t\t'expectedFrameRate': df['SV2_framesPerSecond_aadya'].tolist()}\n",
    "\t\n",
    "    return audio_ellen, video_ellen, audio_aadya, video_aadya\n",
    "\n",
    "\n",
    "def graph_crossover(audio_ellen, video_ellen, audio_aadya, video_aadya):\n",
    "\t'''function to graph the times the each statistic has/doesn't have data for'''\n",
    "\n",
    "\tplt.figure(figsize=(13, 9))\n",
    "\tplot1 = plt.subplot2grid((9, 13), (0, 0), rowspan=9, colspan=6)\n",
    "\tplot2 = plt.subplot2grid((9, 13), (0, 7), rowspan=9, colspan=6)\n",
    "\t\n",
    "\tcolours = [\"forestgreen\", \"lime\", \"mediumseagreen\", \"aquamarine\", \"turquoise\", \"lightseagreen\", \"mediumturquoise\",\"paleturquoise\", \"darkslategray\", \"teal\", \"darkcyan\", \"c\", \"cyan\", \"darkturquoise\", \"cadetblue\", \"powderblue\", \"lightblue\"]\n",
    "\tcol = 0\n",
    "\ty_translation = 0\n",
    "\t\n",
    "\tfor key, val in audio_ellen.items():\n",
    "\t\ttemp_vals = []\n",
    "\t\tfor i in range(len(val)):\n",
    "\t\t\tif val[i] == -1 or val[i] == \"-1\":\n",
    "\t\t\t\ttemp_vals.append(y_translation)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp_vals.append(y_translation + 4)\n",
    "\t\tplot1.plot(range(len(temp_vals)), temp_vals, label=key, color=colours[col])\n",
    "\t\tcol += 1\n",
    "\t\ty_translation += 5\n",
    "\n",
    "\tfor key, val in video_ellen.items():\n",
    "\t\ttemp_vals = []\n",
    "\t\tfor i in range(len(val)):\n",
    "\t\t\tif val[i] == -1 or val[i] == \"-1\":\n",
    "\t\t\t\ttemp_vals.append(y_translation)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp_vals.append(y_translation + 4)\n",
    "\t\tplot1.plot(range(len(temp_vals)), temp_vals, label=key, color=colours[col])\n",
    "\t\tcol += 1\n",
    "\t\ty_translation += 5\n",
    "\n",
    "\tcol = 0\n",
    "\ty_translation = 0\n",
    "\t\n",
    "\tfor key, val in audio_aadya.items():\n",
    "\t\ttemp_vals = []\n",
    "\t\tfor i in range(len(val)):\n",
    "\t\t\tif val[i] == -1 or val[i] == \"-1\":\n",
    "\t\t\t\ttemp_vals.append(y_translation)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp_vals.append(y_translation + 4)\n",
    "\t\tplot2.plot(range(len(temp_vals)), temp_vals, label=key, color=colours[col])\n",
    "\t\tcol += 1\n",
    "\t\ty_translation += 5\n",
    "\n",
    "\tfor key, val in video_aadya.items():\n",
    "\t\ttemp_vals = []\n",
    "\t\tfor i in range(len(val)):\n",
    "\t\t\tif val[i] == -1 or val[i] == \"-1\":\n",
    "\t\t\t\ttemp_vals.append(y_translation)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp_vals.append(y_translation + 4)\n",
    "\t\tplot2.plot(range(len(temp_vals)), temp_vals, label=key, color=colours[col])\n",
    "\t\tcol += 1\n",
    "\t\ty_translation += 5\n",
    "\t\n",
    "\tplot1.legend()\n",
    "\tplot2.legend()\n",
    "\tplot1.set_title(\"Ellen's side\")\n",
    "\tplot2.set_title(\"Aadya's side\")\n",
    "\tplot1.set_yticklabels([])\n",
    "\tplot2.set_yticklabels([])\n",
    "\tplot1.set_xlabel(\"Seconds\")\n",
    "\tplot2.set_xlabel(\"Seconds\")\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def find_non_null_timestamps(stats_dict):\n",
    "\t'''Function to find the roughly 30 second range of timestamps which Web RTC consistently provides data for.'''\n",
    "\n",
    "\tglobal_leftmost = -1\n",
    "\tglobal_rightmost = 99999999999\n",
    "\tfor key, val in stats_dict.items():\n",
    "\t\tleftmost = None\n",
    "\t\trightmost = None\n",
    "\t\tfor i in range(len(val)):\n",
    "\t\t\tif val[i] != -1 and val[i] != \"-1\":\n",
    "\t\t\t\tif leftmost == None:\n",
    "\t\t\t\t\tleftmost = i\n",
    "\t\t\t\t\trightmost = i\n",
    "\t\t\t\tif rightmost != None:\n",
    "\t\t\t\t\trightmost = i\n",
    "\t\t\telif (val[i] == -1 or val[i] == \"-1\") and rightmost != None:\n",
    "\t\t\t\tbreak\n",
    "\t\tif leftmost > global_leftmost:\n",
    "\t\t\tglobal_leftmost = leftmost\n",
    "\t\tif rightmost < global_rightmost:\n",
    "\t\t\tglobal_rightmost = rightmost\n",
    "\n",
    "\treturn global_leftmost + 1, global_rightmost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing the stat crossover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_file_path = '../CSVs/stage_one/treatment'\n",
    "treatment_number = 1\n",
    "audio_ellen, video_ellen, audio_aadya, video_aadya = read_in_relevant_data(parent_file_path, treatment_number)\n",
    "print(find_non_null_timestamps(audio_ellen))\n",
    "graph_crossover(audio_ellen, video_ellen, audio_aadya, video_aadya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main MOS scoring functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Audio stats dictionary contains these params:\n",
    "\n",
    " * packetLoss: 0-100%\n",
    " * bitrate: bps\n",
    " * roundTripTime: ms\n",
    " * bufferDelay: ms\n",
    " * fec: boolean (ony used for audio)\n",
    " * dtx: boolean (ony used for audio)\n",
    "\n",
    "Video stats dictionary contains these params:\n",
    "\n",
    " * packetLoss: 0-100%\n",
    " * bitrate: bps\n",
    " * roundTripTime: ms\n",
    " * bufferDelay: ms\n",
    " * codec: opus / vp8 / vp9 / h264 (only used for video) **EDIT THIS --> maybe add AV1 codec\n",
    " * width: number; Resolution of the video received\n",
    " * expectedWidth: number; Resolution of the rendering widget\n",
    " * height: number; Resolution of the video received\n",
    " * expectedHeight: number; Resolution of the rendering widget\n",
    " * frameRate: number; FrameRate of the video received\n",
    " * expectedFrameRate: number; FrameRate of the video source\n",
    "'''\n",
    "\n",
    "\n",
    "def clamp(val, minimum, maximum):\n",
    "\t'''Function which returns a value if it's within a given range,\n",
    "\tor the minimum of the range or maximum of the range if the value is\n",
    "\toutside of the bounds of the range.'''\n",
    "\tif val >= minimum:\n",
    "\t\tif val <= maximum:\n",
    "\t\t\treturn val\n",
    "\t\telse:\n",
    "\t\t\treturn maximum\n",
    "\telse:\n",
    "\t\treturn minimum\n",
    "\t\n",
    "\n",
    "def score_audio(audio_stats):\n",
    "\t'''Function to generate an MOS score for the audio for a single second of a call. Uses the\n",
    "\tE-Model algorithm.'''\n",
    "\n",
    "\tR0 = 100 #initial rating (starts at max 100)\n",
    "\t\n",
    "    # CALCULATING EQUIPTMENT IMPAIRMENT\n",
    "\tif audio_stats['dtx'] == True:\n",
    "\t\tEI = 8\n",
    "\telif audio_stats['bitRate'] != 0:\n",
    "\t\t\tvalue = 55 - 4.6 * math.log(audio_stats['bitRate'])\n",
    "\t\t\tEI = clamp(value, 0, 30)\n",
    "\telse:\n",
    "\t\tEI = 6\n",
    "\n",
    "    # CALCULATING PACKET LOSS IMPAIRMENT\n",
    "\tPL = audio_stats['packetLoss'] #Packet Loss\n",
    "\t#Packet Loss Robustness Factor\n",
    "\tif audio_stats['fec'] == True:\n",
    "\t\tPLRF = 20\n",
    "\telse:\n",
    "\t\tPLRF = 10   \n",
    "\tPLI = EI + (100 - EI) * (PL / (PL + PLRF)) #Packet Loss Impairment\n",
    "\t\n",
    "    # CALCULATING DELAY IMPAIRMENT\n",
    "\tdelay = 20 + audio_stats['bufferDelay'] + audio_stats['roundTripTime'] / 2 #function of rtt and buffering\n",
    "\tif delay > 150:\n",
    "\t\tDI = delay * 0.03 + (0.1 * (delay - 150)) #Delay Impairment\n",
    "\telse:\n",
    "\t\tDI = delay * 0.03\n",
    "\t\n",
    "    # CALCULATING FINAL SCORE\n",
    "\tR = clamp(R0 - PLI - DI, 0, 100) #Rating\n",
    "\tMOS_raw = 1 + 0.035 * R + (R * (R - 60) * (100 - R) * 7) / 1000000 \n",
    "\tMOS = clamp(round(MOS_raw * 100) / 100, 1, 5) #MOS score bounded between 1-5 to 2 dp\n",
    "\t\n",
    "\treturn MOS\n",
    "\n",
    "\n",
    "def score_video(video_stats):\n",
    "\t'''Function to generate an MOS score for the video for a single second of a call. '''\n",
    "\t\n",
    "\tpixels = video_stats['width'] * video_stats['height']\n",
    "\t\n",
    "\t#increased quality from codec used\n",
    "\tif (video_stats['codec'] == 'VP9') or (video_stats['codec'] == 'AV1'):\n",
    "\t\tcodec_factor = 1.2\n",
    "\telse:\n",
    "\t\tcodec_factor = 1.0\n",
    "\t\n",
    "\tdelay = video_stats['bufferDelay'] + video_stats['roundTripTime'] / 2\n",
    "\t\n",
    "\tFR = video_stats['frameRate']\n",
    "\tif FR != 0:\n",
    "\t\t\n",
    "\t\tbPPPF = (codec_factor * video_stats['bitRate']) / pixels / FR\n",
    "\t\tif bPPPF == 0:\n",
    "\t\t\tbase = 1\n",
    "\t\telse:\n",
    "\t\t\tbase = clamp(0.56 * math.log(bPPPF) + 5.36, 1, 5)\n",
    "\t\tif video_stats['expectedFrameRate'] == 0:\n",
    "\t\t\tMOS_raw = base - delay * 0.002\n",
    "\t\telse:\n",
    "\t\t\tMOS_raw = base - 1.9 * math.log(video_stats['expectedFrameRate'] / FR) - delay * 0.002\n",
    "\t\tMOS = clamp(round(MOS_raw * 100) / 100, 1, 5) #MOS score bounded between 1-5 to 2 dp\n",
    "\t\n",
    "\telse:\n",
    "\t\tMOS = 1\n",
    "\t\n",
    "\treturn MOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_MOS_across_range(all_audio, all_video):\n",
    "    '''function to find the MOS score for every second of a video call, outputiing them \n",
    "    as a list of MOSs across the range of times in a call.'''\n",
    "\n",
    "    audio_leftmost, audio_rightmost = find_non_null_timestamps(all_audio)\n",
    "    video_leftmost, video_rightmost = find_non_null_timestamps(all_video)\n",
    "\n",
    "    audio_MOSs = []\n",
    "    for a in range(audio_leftmost, audio_rightmost + 1):\n",
    "        a_second_stats = {\n",
    "            'packetLoss': all_audio['packetLoss'][a] * 100,\n",
    "            'roundTripTime': all_audio['roundTripTime'][a] * 1000,\n",
    "            'bufferDelay': all_audio['bufferDelay'][a],\n",
    "            'bitRate': all_audio['bitRate'][a],\n",
    "            'fec': eval(all_audio['fec'][a])[1],\n",
    "            'dtx': eval(all_audio['dtx'][a])[0]}\n",
    "        audio_MOSs.append(score_audio(a_second_stats))\n",
    "\n",
    "    video_MOSs = []\n",
    "    for v in range(video_leftmost, video_rightmost + 1):\n",
    "        v_second_stats = {}\n",
    "        for key, val in all_video.items():\n",
    "            v_second_stats[key] = val[v]\n",
    "        v_second_stats['packetLoss'] = v_second_stats['packetLoss'] * 100\n",
    "        video_MOSs.append(score_video(v_second_stats))\n",
    "\n",
    "    return audio_MOSs, video_MOSs\n",
    "\n",
    "def aggregate_MOSs_across_call(MOSs, percentile=5):\n",
    "    '''going for an 'almost minimum' (truncated minimum) aggregation approach: \n",
    "    takes the nth percentile (or (100-n)th percentile worst) to avoid extreme outliers.\n",
    "    5th percentile is chosen as default.'''\n",
    "    data_array = np.array(MOSs)\n",
    "    almost_min_value = np.percentile(data_array, percentile)\n",
    "    return almost_min_value\n",
    "\n",
    "def aggregate_video_and_audio_MOS_harmonic_mean(video_MOS, audio_MOS):\n",
    "    '''aggregation by taking the harmonic mean to give more weighting to the worse value'''\n",
    "    hmean = (2 * video_MOS * audio_MOS) / (video_MOS + audio_MOS)\n",
    "    return round(hmean * 100) / 100\n",
    "\n",
    "def aggregate_ellen_aadya_MOS(ellen_MOS, aadya_MOS):\n",
    "    '''simple aggregation by taking the mean'''\n",
    "    return min(ellen_MOS, aadya_MOS)\n",
    "\n",
    "def find_MOSs(parent_file_path, treatment_number):\n",
    "    '''controller function for finding the MOSs, aggregating appropriately, and outputing them all.'''\n",
    "    audio_ellen, video_ellen, audio_aadya, video_aadya = read_in_relevant_data(parent_file_path, treatment_number)\n",
    "    e_audios, e_videos = find_MOS_across_range(audio_ellen, video_ellen)\n",
    "    a_audios, a_videos = find_MOS_across_range(audio_aadya, video_aadya)\n",
    "    e_audio_mos = aggregate_MOSs_across_call(e_audios)\n",
    "    e_video_mos = aggregate_MOSs_across_call(e_videos)\n",
    "    a_audio_mos = aggregate_MOSs_across_call(a_audios)\n",
    "    a_video_mos = aggregate_MOSs_across_call(a_videos)\n",
    "    e_mos = aggregate_video_and_audio_MOS_harmonic_mean(e_audio_mos, e_video_mos)\n",
    "    a_mos = aggregate_video_and_audio_MOS_harmonic_mean(a_audio_mos, a_video_mos)\n",
    "    agg_audio_mos = aggregate_ellen_aadya_MOS(e_audio_mos, a_audio_mos)\n",
    "    agg_video_mos = aggregate_ellen_aadya_MOS(e_video_mos, a_video_mos)\n",
    "    agg_mos = min(e_mos, a_mos)\n",
    "    return [e_audio_mos, e_video_mos, e_mos, a_audio_mos, a_video_mos, a_mos, agg_audio_mos, agg_video_mos, agg_mos] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the regression tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_regression_table_with_repeats(parsed_CSVs_parent_file_path, test_combos_parent_file_path, regression_table_parent_file_path):\n",
    "    '''Function to create a regression table, with the repeats non-aggregated.'''\n",
    "    \n",
    "    df_ellen = pd.read_csv(test_combos_parent_file_path + \"ellen.csv\")\n",
    "    df_aadya = pd.read_csv(test_combos_parent_file_path + \"aadya.csv\")\n",
    "    treatments = df_aadya['Treatment no.']\n",
    "\t\n",
    "    all_MOSs = []\n",
    "    for i in range(9):\n",
    "        all_MOSs.append([])\n",
    "    for t in treatments:\n",
    "        try:\n",
    "            all_singular_MOSs = find_MOSs(parsed_CSVs_parent_file_path, t)\n",
    "        except Exception as E:\n",
    "            print(\"ERROR!!!!\", t)\n",
    "            print(E)\n",
    "            all_singular_MOSs = [-1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "        for i in range(9):\n",
    "            all_MOSs[i].append(all_singular_MOSs[i])\n",
    "\n",
    "    combined = {\n",
    "\t\t'condition': df_aadya['Condition'],\n",
    "\t\t'ellen_up': df_ellen['Upload'],\n",
    "\t\t'ellen_down': df_ellen['Download'],\n",
    "\t\t'ellen_rtt': df_ellen['Latency'],\n",
    "\t\t'ellen_audio_MOS': all_MOSs[0],\n",
    "\t\t'ellen_video_MOS': all_MOSs[1],\n",
    "\t\t'ellen_MOS': all_MOSs[2],\n",
    "\t\t'aadya_up': df_aadya['Upload'],\n",
    "\t\t'aadya_down': df_aadya['Download'],\n",
    "\t\t'aadya_rtt': df_aadya['Latency'],\n",
    "\t\t'aadya_audio_MOS': all_MOSs[3],\n",
    "\t\t'aadya_video_MOS': all_MOSs[4],\n",
    "\t\t'aadya_MOS': all_MOSs[5],\n",
    "\t\t'agg_audio_MOS': all_MOSs[6],\n",
    "\t\t'agg_video_MOS': all_MOSs[7],\n",
    "\t\t'agg_MOS': all_MOSs[8]}\n",
    "    \n",
    "    df = pd.DataFrame(combined)\n",
    "    df_sorted = df.sort_values(by='condition', ascending=True)\n",
    "    df_sorted.to_csv(regression_table_parent_file_path + \"_with_repeats.csv\", index=False)\n",
    "\n",
    "\n",
    "def prep_final_regression_table(regression_table_parent_file_path, lab_conditions):\n",
    "    '''function which, using the regression table with repeats, aggregates repeats, \n",
    "    and outputs the final table.'''\n",
    "\n",
    "    df = pd.read_csv(regression_table_parent_file_path + \"_with_repeats.csv\")\n",
    "    df['condition'] = df['condition'].astype(float).astype(int) #Convert condition numbers to integers (stripping decimals)\n",
    "    df = df[df['agg_MOS'] != -1.0] # Filter out rows where agg_MOS is -1.0\n",
    "\n",
    "    # Aggregate repeats appropriately: median if in lab, mean if in field\n",
    "    if lab_conditions:\n",
    "        df_aggregated = df.groupby('condition').median().reset_index()\n",
    "    else:\n",
    "        df_aggregated = df.groupby('condition').mean().reset_index()\n",
    "\n",
    "    # Save the aggregated data back to a new CSV\n",
    "    df_aggregated.to_csv(regression_table_parent_file_path + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR!!!! 1\n",
      "[Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment1.csv'\n",
      "ERROR!!!! 5\n",
      "[Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment5.csv'\n",
      "ERROR!!!! 11\n",
      "[Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment11.csv'\n",
      "ERROR!!!! 180\n",
      "[Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment180.csv'\n",
      "ERROR!!!! 249\n",
      "index -1 is out of bounds for axis 0 with size 0\n",
      "ERROR!!!! 252\n",
      "[Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment252.csv'\n",
      "ERROR!!!! 272\n",
      "[Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment272.csv'\n"
     ]
    }
   ],
   "source": [
    "# stage 1:\n",
    "parsed_CSVs_parent_file_path_1 = \"../parsed_CSVs/stage_1/treatment\"\n",
    "test_combos_parent_file_path_1 = \"../test_combos/stage_1/test_combos_shuffled_\"\n",
    "regression_table_parent_file_path_1 = \"../Regression/regression_tables/stage_1/stage1_regression_table\"\n",
    "lab_conditions_1 = True\n",
    "# stage 2:\n",
    "parsed_CSVs_parent_file_path_2 = \"../parsed_CSVs/stage_2/treatment\"\n",
    "test_combos_parent_file_path_2 = \"../test_combos/stage_2/test_combos_shuffled_\"\n",
    "regression_table_parent_file_path_2 = \"../Regression/regression_tables/stage_2/stage2_regression_table\"\n",
    "lab_conditions_2 = True\n",
    "# stage 3:\n",
    "parsed_CSVs_parent_file_path_3 = \"../parsed_CSVs/stage_3/treatment\"\n",
    "test_combos_parent_file_path_3 = \"../test_combos/stage_3/test_combos_shuffled_\"\n",
    "regression_table_parent_file_path_3 = \"../Regression/regression_tables/stage_3/stage3_regression_table\"\n",
    "lab_conditions_3 = True\n",
    "\n",
    "parsed_CSVs_parent_file_path = parsed_CSVs_parent_file_path_3\n",
    "test_combos_parent_file_path = test_combos_parent_file_path_3\n",
    "regression_table_parent_file_path = regression_table_parent_file_path_3\n",
    "lab_conditions = lab_conditions_3\n",
    "prep_regression_table_with_repeats(parsed_CSVs_parent_file_path, test_combos_parent_file_path, regression_table_parent_file_path)\n",
    "prep_final_regression_table(regression_table_parent_file_path, lab_conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fieldwork:\n",
    "test_combos_parent_file_path_field = \"../test_combos/fieldwork/test_combos_shuffled_\"\n",
    "regression_table_parent_file_path_field = \"../Regression/regression_tables/fieldwork/fieldwork_regression_table\"\n",
    "lab_conditions_field = False\n",
    "\n",
    "#DEFINE THE STAT DUMP FILE PATH AND CALL THE FUNCTION FOR RURAL LOCATIONS\n",
    "rural_town_names = [\"colac\", \"dunkeld\", \"ararat\", \"bendigo\", \"elmore\", \"shep\", \"wang\", \"myrtleford\", \"euroa\", \"seymore\"]\n",
    "town_MOSs = []\n",
    "for town_name in rural_town_names:\n",
    "    town_MOSs.append([])\n",
    "    repeated_MOSs = []\n",
    "    for i in range(9):\n",
    "        repeated_MOSs.append([])\n",
    "    \n",
    "    for location in range(1, 4):\n",
    "        parsed_CSVs_parent_file_path = f\"../parsed_CSVs/fieldwork/{town_name}/{town_name}{location}/test\"\n",
    "        try:\n",
    "            MOSs = find_MOSs(parsed_CSVs_parent_file_path, location)\n",
    "        except Exception as E:\n",
    "            print(\"ERROR!!!!\", town_name + str(location), \"did not get an MOS.\")\n",
    "            print(E)\n",
    "            MOSs = [-1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "        for i in range(9):\n",
    "            repeated_MOSs[i].append(MOSs[i])\n",
    "            mean = 0\n",
    "            for mos in repeated_MOSs[i]:\n",
    "                mean += mos\n",
    "            mean = mean / len(repeated_MOSs[i])\n",
    "            repeated_MOSs[i] = mean\n",
    "\n",
    "        writeout_file_path = f\"../parsed_CSVs/fieldwork/{town_name}/{town_name}{location}/test\"\n",
    "urban_suburb_names = [\"dandenong\", \"mordialloc\", \"brighton\", \"toorak\", \"cbd\", \"brunswickwest\", \"northcote\"]\n",
    "\n",
    "#DEFINE THE STAT DUMP FILE PATH AND CALL THE FUNCTION FOR URBAN LOCATIONS\n",
    "for suburb_name in urban_suburb_names:\n",
    "    readin_file_path = f\"stat_dumps/fieldwork/{suburb_name}/test\"\n",
    "    writeout_file_path = f\"parsed_CSVs/fieldwork/{suburb_name}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/colac/colac1/test1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/cv2gnnv97pj8pmspmsfx96v00000gn/T/ipykernel_88417/2284754372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparsed_CSVs_parent_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../parsed_CSVs/fieldwork/colac/colac1/test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfind_MOSs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_CSVs_parent_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9j/cv2gnnv97pj8pmspmsfx96v00000gn/T/ipykernel_88417/1437610916.py\u001b[0m in \u001b[0;36mfind_MOSs\u001b[0;34m(parent_file_path, treatment_number)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_MOSs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m'''controller function for finding the MOSs, aggregating appropriately, and outputing them all.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0maudio_ellen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_ellen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_aadya\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_aadya\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_in_relevant_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0me_audios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_videos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_MOS_across_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_ellen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_ellen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0ma_audios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_videos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_MOS_across_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_aadya\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_aadya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9j/cv2gnnv97pj8pmspmsfx96v00000gn/T/ipykernel_88417/1391713899.py\u001b[0m in \u001b[0;36mread_in_relevant_data\u001b[0;34m(parent_file_path, treatment_number)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_file_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreatment_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#read in as pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     audio_ellen = {\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/colac/colac1/test1.csv'"
     ]
    }
   ],
   "source": [
    "parsed_CSVs_parent_file_path = \"../parsed_CSVs/fieldwork/colac/colac1/test\"\n",
    "find_MOSs(parsed_CSVs_parent_file_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
