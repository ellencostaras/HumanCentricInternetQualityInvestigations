{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple data conversion functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SIMPLE CONVERSION/CLEANING FUNCTIONS\n",
    "\n",
    "def iso_to_unix_time(iso_string):\n",
    "    '''funtion converting ISO time (like in Web RTC) to unix time'''\n",
    "\n",
    "    dt = datetime.strptime(iso_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    unix_time = int(dt.timestamp())\n",
    "    return unix_time\n",
    "\n",
    "def convert_to_sec_minus_10_hrs(timestamp):\n",
    "    '''so for some reason Web RTC's timestamps are 10 hours later than the real time\n",
    "    of the call (24-hour time conversion glitch?). so this function converts a millisecond\n",
    "    unix timestamp into seconds, and takes away 10 hours.'''\n",
    "    new_timestamp = math.floor(float(timestamp) / 1000) - 36000\n",
    "    return new_timestamp\n",
    "\n",
    "def separate_by_comma(text_list):\n",
    "    '''Function which takes a list in text form and converts it to a proper Python list'''\n",
    "    \n",
    "    try:\n",
    "        # Use the `ast.literal_eval` method which safely evaluates a string containing\n",
    "        # a Python literal expression (e.g., a list).\n",
    "        parsed_list = ast.literal_eval(text_list)\n",
    "        \n",
    "        # Ensure the parsed output is a list\n",
    "        if isinstance(parsed_list, list):\n",
    "            return parsed_list\n",
    "        else:\n",
    "            raise ValueError(\"Input is not a list\")\n",
    "    except (ValueError, SyntaxError):\n",
    "        raise ValueError(\"Input is not properly formatted or is not a list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main parsing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(file_path, verbose=False):\n",
    "    '''\n",
    "    This is the nested dictionary structure in the json .txt dump:\n",
    "    dump_file_name -> PeerConnections -> the 3rd dictionary (alphanumeric code) -> stats \n",
    "    \n",
    "    This function parses the relevant stats and saves them in custom data types (dictionaries).\n",
    "    '''\n",
    "    \n",
    "    #opening the dump .txt JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        dump = json.load(file)\n",
    "    \n",
    "    #navigate to where all the stats are stored in the dump\n",
    "    peer_connections = dump.get('PeerConnections', {})\n",
    "    keys_list = list(peer_connections.keys())\n",
    "    third_dictionary = peer_connections.get(keys_list[-1], {})\n",
    "    stats = third_dictionary.get('stats', {})\n",
    "    \n",
    "    #target substrings to pattern match for in stats\n",
    "    target_substrings_IT01V = [\n",
    "        '-[packetsReceived/s]',\n",
    "        '-packetsLost', \n",
    "        '-frameWidth', \n",
    "        '-framesPerSecond', \n",
    "        '-totalFreezesDuration',\n",
    "        '-[bytesReceived_in_bits/s]',\n",
    "        '-totalProcessingDelay',\n",
    "        '-timestamp']\n",
    "    target_substrings_IT01A = [\n",
    "        '-[bytesReceived_in_bits/s]',\n",
    "        '-timestamp']\n",
    "    target_substrings_OT01V = [\n",
    "        '-[packetsSent/s]',\n",
    "        '-[bytesSent_in_bits/s]',\n",
    "        '-frameWidth',\n",
    "        '-framesPerSecond',\n",
    "        '-totalPacketSendDelay',\n",
    "        '-[totalPacketSendDelay/packetsSent_in_ms]',\n",
    "        '-qualityLimitationReason',\n",
    "        '-qualityLimitationResolutionChanges',\n",
    "        '-timestamp']\n",
    "    target_substrings_RIV = [\n",
    "        '-roundTripTime',\n",
    "        '-fractionLost',\n",
    "        '-timestamp']\n",
    "    target_substrings_RIA = [\n",
    "        '-fractionLost',\n",
    "        '-timestamp']\n",
    "    target_substrings_ROA = [\n",
    "        '-roundTripTime',\n",
    "        '-timestamp']\n",
    "    target_substrings_SV2 = [\n",
    "        '-width',\n",
    "        '-framesPerSecond',\n",
    "        '-timestamp']\n",
    "    target_substrings_AP = [\n",
    "        '-totalPlayoutDelay',\n",
    "        '-timestamp']\n",
    "    \n",
    "    #final dictionary data types to store all the values. \n",
    "    #each (None None None) triple will be filled with (values, start time, end time)\n",
    "    target_values_dict_IT01V = {\n",
    "        '-[packetsReceived/s]': (None, None, None),\n",
    "        '-packetsLost': (None, None, None),\n",
    "        '-frameWidth': (None, None, None),\n",
    "        '-totalFreezesDuration': (None, None, None),\n",
    "        '-framesPerSecond': (None, None, None),\n",
    "        '-[bytesReceived_in_bits/s]': (None, None, None),\n",
    "        '-totalProcessingDelay': (None, None, None),\n",
    "        '-jitter': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_IT01A = {\n",
    "        '-[bytesReceived_in_bits/s]': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_OT01V = {\n",
    "        '-[packetsSent/s]': (None, None, None),\n",
    "        '-[bytesSent_in_bits/s]': (None, None, None),\n",
    "        '-frameWidth': (None, None, None),\n",
    "        '-framesPerSecond': (None, None, None),\n",
    "        '-totalPacketSendDelay': (None, None, None),\n",
    "        '-[totalPacketSendDelay/packetsSent_in_ms]': (None, None, None),\n",
    "        '-qualityLimitationReason': (None, None, None),\n",
    "        '-qualityLimitationResolutionChanges': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_RIV = {\n",
    "        '-roundTripTime': (None, None, None),\n",
    "        '-fractionLost': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_RIA = {\n",
    "        '-fractionLost': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_ROA = {\n",
    "        '-roundTripTime': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_SV2 = {\n",
    "        '-width': (None, None, None),\n",
    "        '-framesPerSecond': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    target_values_dict_AP = {\n",
    "        '-totalPlayoutDelay': (None, None, None),\n",
    "        '-timestamp': (None, None, None)}\n",
    "    \n",
    "    #begin searching for the target statistics\n",
    "    for key, value in stats.items():\n",
    "        key_string = str(key)\n",
    "        \n",
    "        # inbound video ones\n",
    "        if key_string[:5] == 'IT01V': \n",
    "            for target_substring in target_substrings_IT01V:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {}) #jump into the innermost dictionary\n",
    "                    if target_values_dict_IT01V[target_substring] == (None, None, None):\n",
    "                        target_values_dict_IT01V[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime'])) #just record whats in the values\n",
    "            #special case for finding jitter because it is a substring of other keys too\n",
    "            if key_string[-7:] == '-jitter':\n",
    "                info = stats.get(key, {})\n",
    "                if target_values_dict_IT01V['-jitter'] == (None, None, None):\n",
    "                    target_values_dict_IT01V['-jitter'] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "        \n",
    "        # inbound audio ones\n",
    "        elif key_string[:5] == 'IT01A':\n",
    "            for target_substring in target_substrings_IT01A:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_IT01A[target_substring] == (None, None, None):\n",
    "                        target_values_dict_IT01A[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "    \n",
    "        # outbound video ones\n",
    "        elif key_string[:5] == 'OT01V':\n",
    "            for target_substring in target_substrings_OT01V:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_OT01V[target_substring] == (None, None, None):\n",
    "                        target_values_dict_OT01V[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "                    \n",
    "        # remote inbound video ones\n",
    "        elif key_string[:3] == 'RIV':\n",
    "            for target_substring in target_substrings_RIV:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_RIV[target_substring] == (None, None, None):\n",
    "                        target_values_dict_RIV[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "        \n",
    "        # remote inbound audio ones\n",
    "        elif key_string[:3] == 'RIA':\n",
    "            for target_substring in target_substrings_RIA:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_RIA[target_substring] == (None, None, None):\n",
    "                        target_values_dict_RIA[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "        \n",
    "        # remote outbound audio ones\n",
    "        elif key_string[:3] == 'ROA':\n",
    "            for target_substring in target_substrings_ROA:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_ROA[target_substring] == (None, None, None):\n",
    "                        target_values_dict_ROA[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "                    \n",
    "        # video source ones\n",
    "        elif key_string[:3] == 'SV2':\n",
    "            for target_substring in target_substrings_SV2:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_SV2[target_substring] == (None, None, None):\n",
    "                        target_values_dict_SV2[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "                    \n",
    "        # audio playout ones\n",
    "        elif key_string[:2] == 'AP':\n",
    "            for target_substring in target_substrings_AP:\n",
    "                if target_substring in key_string:\n",
    "                    info = stats.get(key, {})\n",
    "                    if target_values_dict_AP[target_substring] == (None, None, None):\n",
    "                        target_values_dict_AP[target_substring] = (separate_by_comma(info['values']), iso_to_unix_time(info['startTime']), iso_to_unix_time(info['endTime']))\n",
    "\n",
    "    # Making a global dictionary with unique keys names \n",
    "    single_person_dict = {\n",
    "        'IT01V_packetsRecieved': target_values_dict_IT01V['-[packetsReceived/s]'],\n",
    "        'IT01V_packetsLost': target_values_dict_IT01V['-packetsLost'],\n",
    "        'IT01V_frameWidth': target_values_dict_IT01V['-frameWidth'],\n",
    "        'IT01V_totalFreezesDuration': target_values_dict_IT01V['-totalFreezesDuration'],\n",
    "        'IT01V_framesPerSecond': target_values_dict_IT01V['-framesPerSecond'],\n",
    "        'IT01V_bytesReceived_in_bits/s': target_values_dict_IT01V['-[bytesReceived_in_bits/s]'],\n",
    "        'IT01V_totalProcessingDelay': target_values_dict_IT01V['-totalProcessingDelay'],\n",
    "        'IT01V_jitter': target_values_dict_IT01V['-jitter'],\n",
    "        'IT01V_timestamps': target_values_dict_IT01V['-timestamp'],\n",
    "        'IT01A_bytesReceived_in_bits/s': target_values_dict_IT01A['-[bytesReceived_in_bits/s]'],\n",
    "        'IT01A_timestamps': target_values_dict_IT01A['-timestamp'],\n",
    "        'OT01V_packetsSent/s': target_values_dict_OT01V['-[packetsSent/s]'],\n",
    "        'OT01V_bytesSent_in_bits/s': target_values_dict_OT01V['-[bytesSent_in_bits/s]'],\n",
    "        'OT01V_frameWidth': target_values_dict_OT01V['-frameWidth'],\n",
    "        'OT01V_framesPerSecond': target_values_dict_OT01V['-framesPerSecond'],\n",
    "        'OT01V_totalPacketSendDelay': target_values_dict_OT01V['-totalPacketSendDelay'],\n",
    "        'OT01V_totalPacketSendDelay/packetsSent_in_ms': target_values_dict_OT01V['-[totalPacketSendDelay/packetsSent_in_ms]'],\n",
    "        'OT01V_qualityLimitationReason': target_values_dict_OT01V['-qualityLimitationReason'],\n",
    "        'OT01V_qualityLimitationResolutionChanges': target_values_dict_OT01V['-qualityLimitationResolutionChanges'],\n",
    "        'OT01V_timestamps': target_values_dict_OT01V['-timestamp'],\n",
    "        'RIV_roundTripTime': target_values_dict_RIV['-roundTripTime'],\n",
    "        'RIV_fractionLost': target_values_dict_RIV['-fractionLost'],\n",
    "        'RIV_timestamps': target_values_dict_RIV['-timestamp'],\n",
    "        'RIA_fractionLost': target_values_dict_RIA['-fractionLost'],\n",
    "        'RIA_timestamps': target_values_dict_RIA['-timestamp'],\n",
    "        'ROA_roundTripTime': target_values_dict_ROA['-roundTripTime'],\n",
    "        'ROA_timestamps': target_values_dict_ROA['-timestamp'],\n",
    "        'SV2_width': target_values_dict_SV2['-width'],\n",
    "        'SV2_framesPerSecond': target_values_dict_SV2['-framesPerSecond'],\n",
    "        'SV2_timestamps': target_values_dict_SV2['-timestamp'],\n",
    "        'AP_totalPlayoutDelay': target_values_dict_AP['-totalPlayoutDelay'],\n",
    "        'AP_timestamps': target_values_dict_AP['-timestamp']}\n",
    "    \n",
    "    if verbose:    \n",
    "        for key, value in single_person_dict.items():\n",
    "            print(key, \": \", value[0])\n",
    "            print(\"Start Time: \", value[1], \" |  End Time: \", value[2])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "    return single_person_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and formatting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dictionaries(dict_ellen, dict_aadya):\n",
    "    global_dict = {}\n",
    "    for key, val in dict_ellen.items():\n",
    "        key_string = str(key)\n",
    "        global_dict[key_string + \"_ellen\"] = val\n",
    "        global_dict[key_string + \"_aadya\"] = dict_aadya[key_string]\n",
    "    return global_dict\n",
    "\n",
    "\n",
    "def populate_global_table(global_dict, mistake_tally):\n",
    "\n",
    "    global_start = 999999999999999999999999\n",
    "    global_end = 0\n",
    "    \n",
    "    for key, val in global_dict.items():\n",
    "        start_time = val[1]\n",
    "        end_time = val[2]\n",
    "        if start_time < global_start:\n",
    "            global_start = start_time\n",
    "        if end_time > global_end:\n",
    "            global_end = end_time\n",
    "\n",
    "    total_time = global_end - global_start + 1\n",
    "\n",
    "    #populate a rectangular table with -1 for every timestamp\n",
    "    global_table = []\n",
    "    for key, val in global_dict.items():\n",
    "        global_table.append([-1] * total_time)\n",
    "\n",
    "    #truncate timestamps to basic unix timecodes, (round to closest second)\n",
    "    for key, val in global_dict.items():\n",
    "        key_string = str(key)\n",
    "        if \"timestamps\" in key_string:\n",
    "            old_timestamps = val[0]\n",
    "            new_timestamps = []\n",
    "            for time in old_timestamps:\n",
    "                new_timestamps.append(convert_to_sec_minus_10_hrs(time))\n",
    "            global_dict[key] = (new_timestamps, val[1], val[2])\n",
    "\n",
    "    #replace -1s in the timestamps where data exists for every stat for ellen\n",
    "    row_number = 0\n",
    "    for key, val in global_dict.items():\n",
    "        key_string = str(key)\n",
    "        person = key_string[-5:]\n",
    "        if key_string[:5] == 'IT01V': \n",
    "            timestamps = global_dict['IT01V_timestamps_' + person][0]\n",
    "        elif key_string[:5] == 'IT01A':\n",
    "            timestamps = global_dict['IT01A_timestamps_' + person][0]\n",
    "        elif key_string[:5] == 'OT01V':\n",
    "            timestamps = global_dict['OT01V_timestamps_' + person][0]\n",
    "        elif key_string[:3] == 'RIV':\n",
    "            timestamps = global_dict['RIV_timestamps_' + person][0]\n",
    "        elif key_string[:3] == 'RIA':\n",
    "            timestamps = global_dict['RIA_timestamps_' + person][0]\n",
    "        elif key_string[:3] == 'ROA':\n",
    "            timestamps = global_dict['ROA_timestamps_' + person][0]\n",
    "        elif key_string[:3] == 'SV2':\n",
    "            timestamps = global_dict['SV2_timestamps_' + person][0]\n",
    "        elif key_string[:2] == 'AP':\n",
    "            timestamps = global_dict['AP_timestamps_' + person][0]\n",
    "\n",
    "        start_time = val[1]\n",
    "        end_time = val[2]\n",
    "        \n",
    "        # Timing error handling:\n",
    "        if start_time < timestamps[0]:\n",
    "            start_time_index = 0 \n",
    "            mistake_tally['start time errors'] += 1\n",
    "        else:\n",
    "            start_time_index = None\n",
    "        if end_time > timestamps[-1]:\n",
    "            end_time_index = 0\n",
    "            mistake_tally['end time errors'] += 1\n",
    "        else:\n",
    "            start_time_index = None\n",
    "        \n",
    "        for time in range(len(timestamps)):\n",
    "            if timestamps[time] == start_time:\n",
    "                start_time_index = time\n",
    "            if timestamps[time] == end_time:\n",
    "                end_time_index = time \n",
    "        appropriate_timestamps = timestamps[start_time_index : end_time_index + 1]\n",
    "        \n",
    "        #sneaky cleaning in the cases where Web RTC makes a mistake:\n",
    "        if start_time < timestamps[0]:\n",
    "            if len(val[0]) > len(appropriate_timestamps):\n",
    "                difference = len(val[0]) - len(appropriate_timestamps)\n",
    "            val = (val[0][difference:], val[1], val[2])\n",
    "        if end_time > timestamps[-1]:\n",
    "            if len(val[0]) > len(appropriate_timestamps):\n",
    "                difference = len(val[0]) - len(appropriate_timestamps)\n",
    "            val = (val[0][:-difference], val[1], val[2])\n",
    "        \n",
    "        if len(appropriate_timestamps) != len(val[0]):\n",
    "            #print(key, \"| len_times:\", len(appropriate_timestamps), \"| len_vals:\", len(val[0]))\n",
    "            difference = len(appropriate_timestamps) - len(val[0])\n",
    "            if difference == 1:\n",
    "                mistake_tally['missed val errors (off by 1 only)'] += 1\n",
    "            elif difference > 1:\n",
    "                mistake_tally['missed val errors (off by > 1)'].append(difference)\n",
    "            elif difference == -1:\n",
    "                mistake_tally['extra vals errors (off by 1 only)'] += 1\n",
    "                print(key, \"| len_times:\", len(appropriate_timestamps), \"| len_vals:\", len(val[0]))\n",
    "            elif difference < -1:\n",
    "                mistake_tally['extra vals errors (off by > 1)'].append(-1 * difference)\n",
    "            appropriate_timestamps = appropriate_timestamps[:-difference] #bad but neccessary assumption LIMITATION LIMITATION LIMITATION\n",
    "\n",
    "        \n",
    "        for t in range(len(appropriate_timestamps)):\n",
    "            time = appropriate_timestamps[t]\n",
    "            global_table[row_number][time - global_start] = val[0][t]\n",
    "        row_number += 1\n",
    "    \n",
    "    return global_table\n",
    "\n",
    "\n",
    "def writeout(global_table, global_dict, treatment_number):\n",
    "\n",
    "    # Flip the table (rows -> columns and columns -> rows) for writeout nice-ness\n",
    "    global_table_flipped = []\n",
    "    for col in range(len(global_table[0])):\n",
    "        row_flipped = []\n",
    "        for row in range(len(global_table)):\n",
    "            row_flipped.append(global_table[row][col])\n",
    "        global_table_flipped.append(row_flipped)\n",
    "\n",
    "    # Write out to a CSV\n",
    "    output_file = f\"CSVs/stage_one/treatment{treatment_number}.csv\"\n",
    "    with open(output_file, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        header = []\n",
    "        for key, val in global_dict.items():\n",
    "            header.append(key)\n",
    "        writer.writerow(header)\n",
    "        for row in global_table_flipped:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Data has been written to {output_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clean_writeout(parent_file_path, treatment_number, mistake_tally, read_only=False, verbose=False):\n",
    "    file_path_ellen = parent_file_path + str(treatment_number) + \"_ellen.txt\"\n",
    "    file_path_aadya = parent_file_path + str(treatment_number) + \"_aadya.txt\"\n",
    "    dict_ellen = get_stats(file_path_ellen)\n",
    "    dict_aadya = get_stats(file_path_aadya)\n",
    "    global_dict = combine_dictionaries(dict_ellen, dict_aadya)\n",
    "    global_table = populate_global_table(global_dict, mistake_tally)\n",
    "    if not read_only:\n",
    "        writeout(global_table, global_dict, treatment_number)\n",
    "\n",
    "def parse_range(parent_file_path, lowest_treatment, highest_treatment, read_only=False, verbose=False):\n",
    "    mistake_tally = {\n",
    "        'start time errors': 0,\n",
    "        'end time errors': 0,\n",
    "        'missed val errors (off by 1 only)': 0,\n",
    "        'missed val errors (off by > 1)': [],\n",
    "        'extra vals errors (off by 1 only)': 0,\n",
    "        'extra vals errors (off by > 1)': []     \n",
    "    }\n",
    "\n",
    "    for i in range(lowest_treatment, highest_treatment + 1):\n",
    "        print(\"Parsing Treatment\", i)\n",
    "        parse_clean_writeout(parent_file_path, i, mistake_tally, read_only, verbose)\n",
    "\n",
    "    print(\"\\nParsing complete! Here is the number Web RTC timing errors encountered...\")\n",
    "    print(\"___________________________________________________________________________\")\n",
    "    for key, val in mistake_tally.items():\n",
    "        print(key + \":\", val)\n",
    "    print(\"___________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time start: 1725321938\n",
      "time end: 1725322045\n",
      "time stamps: 16\n",
      "fps start: 1725321940\n",
      "fps end: 1725322045\n",
      "fps vals: 14\n",
      "\n",
      "\n",
      "[1725321938, 1725321940, 1725321942, 1725321944, 1725321946, 1725321948, 1725321950, 1725321952, 1725321954, 1725321956, 1725321958, 1725321960, 1725321962, 1725321964, 1725321985, 1725322045]\n",
      "yep\n",
      "yep\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(\"time start:\", iso_to_unix_time(\"2024-09-03T10:05:38.068Z\"))\n",
    "print(\"time end:\", iso_to_unix_time(\"2024-09-03T10:07:25.067Z\"))\n",
    "stamps = [1725357938068.841,1725357940068.595,1725357942068.448,1725357944068.633,1725357946068.095,1725357948067.79,1725357950068.565,1725357952068.084,1725357954068.18,1725357956068.516,1725357958068.313,1725357960068.269,1725357962067.765,1725357964068.264,1725357985067.976,1725358045067.41]\n",
    "print(\"time stamps:\", len(stamps))\n",
    "print(\"fps start:\", iso_to_unix_time(\"2024-09-03T10:05:40.068Z\"))\n",
    "print(\"fps end:\", iso_to_unix_time(\"2024-09-03T10:07:25.067Z\"))\n",
    "print(\"fps vals:\", len([10,19,26,31,28,30,30,26,33,31,32,31,29,30]))\n",
    "print(\"\\n\")\n",
    "new = []\n",
    "for stamp in stamps:\n",
    "    new.append(convert_to_sec_minus_10_hrs(stamp))\n",
    "print(new)\n",
    "for dud in range(len(new)):\n",
    "    dude = new[dud]\n",
    "    if dude == iso_to_unix_time(\"2024-09-03T10:05:40.068Z\"):\n",
    "        indi1 = dud\n",
    "        print(\"yep\")\n",
    "    elif dude == iso_to_unix_time(\"2024-09-03T10:07:25.067Z\"):\n",
    "        print(\"yep\")\n",
    "        indi2 = dud\n",
    "print(len(stamps[indi1:indi2+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Treatment 229\n",
      "RIV_roundTripTime_aadya | len_times: 27 | len_vals: 28\n",
      "RIV_fractionLost_aadya | len_times: 27 | len_vals: 28\n",
      "RIV_timestamps_aadya | len_times: 27 | len_vals: 28\n",
      "RIA_fractionLost_aadya | len_times: 27 | len_vals: 28\n",
      "RIA_timestamps_aadya | len_times: 27 | len_vals: 28\n",
      "ROA_roundTripTime_aadya | len_times: 27 | len_vals: 28\n",
      "ROA_timestamps_aadya | len_times: 27 | len_vals: 28\n",
      "Data has been written to CSVs/stage_one/treatment229.csv\n",
      "\n",
      "Parsing complete! Here is the number Web RTC timing errors encountered...\n",
      "___________________________________________________________________________\n",
      "start time errors: 0\n",
      "end time errors: 0\n",
      "missed val errors (off by 1 only): 0\n",
      "missed val errors (off by > 1): []\n",
      "extra vals errors (off by 1 only): 7\n",
      "extra vals errors (off by > 1): []\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#file paths for testing_9_Aug\n",
    "file_path_parent_01 = \"testing_stats/testing_9_Aug/treatment\"\n",
    "#file path parent for testing_13_Aug\n",
    "file_path_parent_02 = \"testing_stats/testing_13_Aug/treatment\" \n",
    "#file path parent for testing_27_Aug\n",
    "file_path_parent_03 = \"testing_stats/testing_27_Aug/treatment\"\n",
    "#file path parent for testing_30_Aug\n",
    "file_path_parent_04 = \"testing_stats/testing_30_Aug/treatment\"\n",
    "#file path parent for stage one treatments\n",
    "file_path_parent_05 = \"testing_stats/stage_1/treatment\"\n",
    "\n",
    "lowest_treatment_number = 1\n",
    "highest_treatment_number = 300\n",
    "read_only_status = False\n",
    "verbose_status = False\n",
    "parse_range(file_path_parent_05, lowest_treatment_number, highest_treatment_number, read_only_status, verbose_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
