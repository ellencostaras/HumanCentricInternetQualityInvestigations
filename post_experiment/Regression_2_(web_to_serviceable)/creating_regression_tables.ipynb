{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_null_timestamps(stats_dict):\n",
    "\t'''Function to find the roughly 30 second range of timestamps which Web RTC consistently provides data for.'''\n",
    "\n",
    "\tglobal_leftmost = -1\n",
    "\tglobal_rightmost = 99999999999\n",
    "\tfor key, val in stats_dict.items():\n",
    "\t\tleftmost = None\n",
    "\t\trightmost = None\n",
    "\t\tfor i in range(len(val)):\n",
    "\t\t\tif val[i] != -1 and val[i] != \"-1\":\n",
    "\t\t\t\tif leftmost == None:\n",
    "\t\t\t\t\tleftmost = i\n",
    "\t\t\t\t\trightmost = i\n",
    "\t\t\t\tif rightmost != None:\n",
    "\t\t\t\t\trightmost = i\n",
    "\t\t\telif (val[i] == -1 or val[i] == \"-1\") and rightmost != None:\n",
    "\t\t\t\tbreak\n",
    "\t\tif leftmost > global_leftmost:\n",
    "\t\t\tglobal_leftmost = leftmost\n",
    "\t\tif rightmost < global_rightmost:\n",
    "\t\t\tglobal_rightmost = rightmost\n",
    "\n",
    "\treturn global_leftmost + 1, global_rightmost\n",
    "\n",
    "\n",
    "def aggregate_across_call_single_stat(stat_list, percentile, leftmost, rightmost):\n",
    "\t'''function to aggregate Web RTC stat for a whole call into one'''\n",
    "\t\n",
    "\tif rightmost - leftmost <= 0:\n",
    "\t\traise ValueError(\"Error: Statistic found for which Web RTC recorded no data for.\") \n",
    "\telse:\n",
    "\t\tstat_list_reduced = np.array(stat_list[leftmost : rightmost + 1])\n",
    "\t\tagg_value = np.percentile(stat_list_reduced, percentile)\n",
    "\t\treturn agg_value\n",
    "\n",
    "\n",
    "def find_agg_stats_single_call(parent_file_path, treatment):\n",
    "\t'''function which outputs a list of aggregated statistics (one for every\n",
    "    Web RTC stat parsed), across the call'''\n",
    "\t\n",
    "\tfile_path = parent_file_path + str(treatment) + \".csv\"\n",
    "\tdf = pd.read_csv(file_path) #read in as pandas data frame\n",
    "\tleftmost, rightmost = find_non_null_timestamps(df.to_dict(orient='list'))\n",
    "\t\n",
    "\tsmall_is_bad = [\n",
    "\t\t          \"IT01V_packetsRecieved_ellen\",\n",
    "\t\t\t      \"IT01V_packetsRecieved_aadya\",\n",
    "\t\t\t\t  \"IT01V_frameWidth_ellen\",\n",
    "\t\t\t\t  \"IT01V_frameWidth_aadya\",\n",
    "\t\t\t\t  \"IT01V_frameHeight_ellen\",\n",
    "\t\t\t\t  \"IT01V_frameHeight_aadya\",\n",
    "\t\t\t\t  \"IT01V_framesPerSecond_ellen\",\n",
    "\t\t\t\t  \"IT01V_framesPerSecond_aadya\",\n",
    "\t\t\t\t  \"IT01V_bytesReceived_in_bits/s_ellen\",\n",
    "\t\t\t\t  \"IT01V_bytesReceived_in_bits/s_aadya\",\n",
    "\t\t\t\t  \"IT01A_bytesReceived_in_bits/s_ellen\",\n",
    "\t\t\t\t  \"IT01A_bytesReceived_in_bits/s_aadya\",\n",
    "\t\t\t\t  \"OT01V_packetsSent/s_ellen\",\n",
    "\t\t\t\t  \"OT01V_packetsSent/s_aadya\",\n",
    "\t\t\t\t  \"OT01V_bytesSent_in_bits/s_ellen\",\n",
    "\t\t\t\t  \"OT01V_bytesSent_in_bits/s_aadya\",\n",
    "\t\t\t\t  \"OT01V_frameWidth_ellen\",\n",
    "\t\t\t\t  \"OT01V_frameWidth_aadya\",\n",
    "\t\t\t\t  \"OT01V_framesPerSecond_ellen\",\n",
    "\t\t\t\t  \"OT01V_framesPerSecond_aadya\",\n",
    "\t\t\t\t  ]\n",
    "\tbig_is_bad = [\n",
    "\t\t\t\t  \"IT01V_packetsLost_ellen\", \n",
    "\t\t\t\t  \"IT01V_packetsLost_aadya\",\n",
    "\t\t\t\t  \"IT01V_totalFreezesDuration_ellen\",\n",
    "\t\t\t\t  \"IT01V_totalFreezesDuration_aadya\",\n",
    "\t\t\t\t  \"IT01V_totalProcessingDelay_ellen\",\n",
    "\t\t\t\t  \"IT01V_totalProcessingDelay_aadya\",\n",
    "\t\t\t\t  \"IT01V_jitter_ellen\",\n",
    "\t\t\t\t  \"IT01V_jitter_aadya\",\n",
    "\t\t\t\t  \"IT01V_jitterBufferDelay/emissions_ellen\",\n",
    "\t\t\t\t  \"IT01V_jitterBufferDelay/emissions_aadya\",\n",
    "\t\t\t\t  \"IT01A_jitterBufferDelay/emissions_ellen\",\n",
    "\t\t\t\t  \"IT01A_jitterBufferDelay/emissions_aadya\",\n",
    "\t\t\t\t  \"OT01V_totalPacketSendDelay_ellen\",\n",
    "\t\t\t\t  \"OT01V_totalPacketSendDelay_aadya\",\n",
    "\t\t\t\t  \"OT01V_totalPacketSendDelay/packetsSent_in_ms_ellen\",\n",
    "\t\t\t\t  \"OT01V_totalPacketSendDelay/packetsSent_in_ms_aadya\",\n",
    "\t\t\t\t  \"RIV_roundTripTime_ellen\",\n",
    "\t\t\t\t  \"RIV_roundTripTime_aadya\",\n",
    "\t\t\t\t  \"RIV_fractionLost_ellen\",\n",
    "\t\t\t\t  \"RIV_fractionLost_aadya\",\n",
    "\t\t\t\t  \"RIA_fractionLost_ellen\",\n",
    "\t\t\t\t  \"RIA_fractionLost_aadya\",\n",
    "\t\t\t\t  \"RIA_roundTripTime_ellen\",\n",
    "\t\t\t\t  \"RIA_roundTripTime_aadya\",\n",
    "\t\t\t\t  \"ROA_roundTripTime_ellen\",\n",
    "\t\t\t\t  \"ROA_roundTripTime_aadya\",\n",
    "\t\t\t\t  \"AP_totalPlayoutDelay_ellen\",\n",
    "\t\t\t\t  \"AP_totalPlayoutDelay_aadya\"]\n",
    "                  \n",
    "\tagg_values = []\n",
    "\tfor col_name, col_data in df.iteritems():\n",
    "\t\tif col_name in small_is_bad:\n",
    "\t\t\tpercentile = 10 \n",
    "\t\t\tagg_values.append(aggregate_across_call_single_stat(col_data, percentile, leftmost, rightmost))\n",
    "\t\telif col_name in big_is_bad:\n",
    "\t\t\tpercentile = 90\n",
    "\t\t\tagg_values.append(aggregate_across_call_single_stat(col_data, percentile, leftmost, rightmost))\n",
    "\t\t\t\n",
    "\treturn agg_values\n",
    "\t\t\n",
    "\n",
    "def create_regression_table(readin_parent_file_path, writeout_file_path, lowest_treatment_number, highest_treatment_number):\n",
    "\t\n",
    "    header = [\n",
    "\t\t\"call_number\",\n",
    "\t\t\"IT01V_packetsRecieved_ellen\",\n",
    "        \"IT01V_packetsRecieved_aadya\",\n",
    "\t\t\"IT01V_packetsLost_ellen\", \n",
    "        \"IT01V_packetsLost_aadya\",\n",
    "        \"IT01V_frameWidth_ellen\",\n",
    "        \"IT01V_frameWidth_aadya\",\n",
    "        \"IT01V_frameHeight_ellen\",\n",
    "        \"IT01V_frameHeight_aadya\",\n",
    "\t\t\"IT01V_totalFreezesDuration_ellen\",\n",
    "        \"IT01V_totalFreezesDuration_aadya\",\n",
    "        \"IT01V_framesPerSecond_ellen\",\n",
    "        \"IT01V_framesPerSecond_aadya\",\n",
    "        \"IT01V_bytesReceived_in_bits_s_ellen\",\n",
    "        \"IT01V_bytesReceived_in_bits_s_aadya\",\n",
    "\t\t\"IT01V_totalProcessingDelay_ellen\",\n",
    "        \"IT01V_totalProcessingDelay_aadya\",\n",
    "        \"IT01V_jitter_ellen\",\n",
    "        \"IT01V_jitter_aadya\",\n",
    "        \"IT01V_jitterBufferDelay_emissions_ellen\",\n",
    "        \"IT01V_jitterBufferDelay_emissions_aadya\",\n",
    "        \"IT01A_bytesReceived_in_bits_s_ellen\",\n",
    "        \"IT01A_bytesReceived_in_bits_s_aadya\",\n",
    "\t\t\"IT01A_jitterBufferDelay_emissions_ellen\",\n",
    "        \"IT01A_jitterBufferDelay_emissions_aadya\",\n",
    "        \"OT01V_packetsSent_s_ellen\",\n",
    "        \"OT01V_packetsSent_s_aadya\",\n",
    "        \"OT01V_bytesSent_in_bits_s_ellen\",\n",
    "        \"OT01V_bytesSent_in_bits_s_aadya\",\n",
    "        \"OT01V_frameWidth_ellen\",\n",
    "        \"OT01V_frameWidth_aadya\",\n",
    "        \"OT01V_framesPerSecond_ellen\",\n",
    "        \"OT01V_framesPerSecond_aadya\",\n",
    "\t\t\"OT01V_totalPacketSendDelay_ellen\",\n",
    "        \"OT01V_totalPacketSendDelay_aadya\",\n",
    "        \"OT01V_totalPacketSendDelay_packetsSent_in_ms_ellen\",\n",
    "        \"OT01V_totalPacketSendDelay_packetsSent_in_ms_aadya\",\n",
    "        \"RIV_roundTripTime_ellen\",\n",
    "        \"RIV_roundTripTime_aadya\",\n",
    "        \"RIV_fractionLost_ellen\",\n",
    "        \"RIV_fractionLost_aadya\",\n",
    "        \"RIA_fractionLost_ellen\",\n",
    "        \"RIA_fractionLost_aadya\",\n",
    "        \"RIA_roundTripTime_ellen\",\n",
    "        \"RIA_roundTripTime_aadya\",\n",
    "        \"ROA_roundTripTime_ellen\",\n",
    "        \"ROA_roundTripTime_aadya\",\n",
    "        \"AP_totalPlayoutDelay_ellen\",\n",
    "        \"AP_totalPlayoutDelay_aadya\"\n",
    "    ]\n",
    "\t# Write out to a CSV\n",
    "    with open(writeout_file_path, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(header)\n",
    "        for treatment in tqdm(range(lowest_treatment_number, highest_treatment_number + 1)):\n",
    "            try:\n",
    "                row = [treatment] + find_agg_stats_single_call(readin_parent_file_path, treatment)\n",
    "                writer.writerow(row)\n",
    "            except Exception as E:\n",
    "                print(f\"WARNING: unable to generate aggregate statistics for treatment {treatment} due to ...\")\n",
    "                print(\"      \", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 265/300 [00:03<00:00, 69.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 254 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 68.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# STAGE 1\n",
    "\n",
    "readin_parent_file_path = \"../parsed_CSVs/stage_1/treatment\"\n",
    "writeout_file_path = \"independent_vars_tables/stage_1_independent_vars_table.csv\"\n",
    "lowest_treatment_number = 1\n",
    "highest_treatment_number = 300\n",
    "create_regression_table(readin_parent_file_path, writeout_file_path, lowest_treatment_number, highest_treatment_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/300 [00:00<00:04, 59.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 33 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 185/300 [00:03<00:01, 67.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 178 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for treatment 184 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for treatment 187 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 237/300 [00:03<00:00, 69.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 224 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for treatment 226 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 268/300 [00:04<00:00, 70.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 256 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_2/treatment256.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 63.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 298 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# STAGE 2\n",
    "\n",
    "readin_parent_file_path = \"../parsed_CSVs/stage_2/treatment\"\n",
    "writeout_file_path = \"independent_vars_tables/stage_2_independent_vars_table.csv\"\n",
    "lowest_treatment_number = 1\n",
    "highest_treatment_number = 300\n",
    "create_regression_table(readin_parent_file_path, writeout_file_path, lowest_treatment_number, highest_treatment_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/300 [00:00<00:03, 81.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 1 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment1.csv'\n",
      "WARNING: unable to generate aggregate statistics for treatment 5 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment5.csv'\n",
      "WARNING: unable to generate aggregate statistics for treatment 11 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment11.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 194/300 [00:02<00:01, 72.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 180 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment180.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 257/300 [00:03<00:00, 72.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 249 due to ...\n",
      "       Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for treatment 252 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment252.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 281/300 [00:03<00:00, 72.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for treatment 272 due to ...\n",
      "       [Errno 2] No such file or directory: '../parsed_CSVs/stage_3/treatment272.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 70.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# STAGE 3\n",
    "\n",
    "readin_parent_file_path = \"../parsed_CSVs/stage_3/treatment\"\n",
    "writeout_file_path = \"independent_vars_tables/stage_3_independent_vars_table.csv\"\n",
    "lowest_treatment_number = 1\n",
    "highest_treatment_number = 300\n",
    "create_regression_table(readin_parent_file_path, writeout_file_path, lowest_treatment_number, highest_treatment_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For fieldwork stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unable to generate aggregate statistics for colac11 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/colac/colac1/test1.csv'\n",
      "WARNING: unable to generate aggregate statistics for colac13 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/colac/colac1/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for colac21 due to...\n",
      "        Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for colac22 due to...\n",
      "        Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for colac32 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/colac/colac3/test2.csv'\n",
      "WARNING: unable to generate aggregate statistics for colac33 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/colac/colac3/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for dunkeld11 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/dunkeld/dunkeld1/test1.csv'\n",
      "WARNING: unable to generate aggregate statistics for dunkeld13 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/dunkeld/dunkeld1/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for dunkeld21 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/dunkeld/dunkeld2/test1.csv'\n",
      "WARNING: unable to generate aggregate statistics for dunkeld22 due to...\n",
      "        Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for dunkeld32 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/dunkeld/dunkeld3/test2.csv'\n",
      "WARNING: unable to generate aggregate statistics for ararat33 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/ararat/ararat3/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for bendigo31 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/bendigo/bendigo3/test1.csv'\n",
      "WARNING: unable to generate aggregate statistics for elmore33 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/elmore/elmore3/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for myrtleford31 due to...\n",
      "        Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for myrtleford33 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/myrtleford/myrtleford3/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for euroa33 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/euroa/euroa3/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for seymore22 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/seymore/seymore2/test2.csv'\n",
      "WARNING: unable to generate aggregate statistics for seymore23 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/seymore/seymore2/test3.csv'\n",
      "WARNING: unable to generate aggregate statistics for seymore32 due to...\n",
      "        [Errno 2] No such file or directory: '../parsed_CSVs/fieldwork/seymore/seymore3/test2.csv'\n",
      "WARNING: unable to generate aggregate statistics for mordialloc1\n",
      "        Error: Statistic found for which Web RTC recorded no data for.\n",
      "WARNING: unable to generate aggregate statistics for mordialloc2\n",
      "        Error: Statistic found for which Web RTC recorded no data for.\n"
     ]
    }
   ],
   "source": [
    "# Fieldwork\n",
    "\n",
    "rural_town_names = [\"colac\", \"dunkeld\", \"ararat\", \"bendigo\", \"elmore\", \"shep\", \"wang\", \"myrtleford\", \"euroa\", \"seymore\"]\n",
    "urban_suburb_names = [\"dandenong\", \"mordialloc\", \"brighton\", \"toorak\", \"cbd\", \"brunswickwest\", \"northcote\"]\n",
    "\n",
    "writeout_file_path = \"independent_vars_tables/fieldwork_independent_vars_table.csv\"\n",
    "\n",
    "header = [\n",
    "\t\t\"ID\",\n",
    "\t\t\"IT01V_packetsRecieved_ellen\",\n",
    "        \"IT01V_packetsRecieved_aadya\",\n",
    "\t\t\"IT01V_packetsLost_ellen\", \n",
    "        \"IT01V_packetsLost_aadya\",\n",
    "        \"IT01V_frameWidth_ellen\",\n",
    "        \"IT01V_frameWidth_aadya\",\n",
    "        \"IT01V_frameHeight_ellen\",\n",
    "        \"IT01V_frameHeight_aadya\",\n",
    "\t\t\"IT01V_totalFreezesDuration_ellen\",\n",
    "        \"IT01V_totalFreezesDuration_aadya\",\n",
    "        \"IT01V_framesPerSecond_ellen\",\n",
    "        \"IT01V_framesPerSecond_aadya\",\n",
    "        \"IT01V_bytesReceived_in_bits_s_ellen\",\n",
    "        \"IT01V_bytesReceived_in_bits_s_aadya\",\n",
    "\t\t\"IT01V_totalProcessingDelay_ellen\",\n",
    "        \"IT01V_totalProcessingDelay_aadya\",\n",
    "        \"IT01V_jitter_ellen\",\n",
    "        \"IT01V_jitter_aadya\",\n",
    "        \"IT01V_jitterBufferDelay_emissions_ellen\",\n",
    "        \"IT01V_jitterBufferDelay_emissions_aadya\",\n",
    "        \"IT01A_bytesReceived_in_bits_s_ellen\",\n",
    "        \"IT01A_bytesReceived_in_bits_s_aadya\",\n",
    "\t\t\"IT01A_jitterBufferDelay_emissions_ellen\",\n",
    "        \"IT01A_jitterBufferDelay_emissions_aadya\",\n",
    "        \"OT01V_packetsSent_s_ellen\",\n",
    "        \"OT01V_packetsSent_s_aadya\",\n",
    "        \"OT01V_bytesSent_in_bits_s_ellen\",\n",
    "        \"OT01V_bytesSent_in_bits_s_aadya\",\n",
    "        \"OT01V_frameWidth_ellen\",\n",
    "        \"OT01V_frameWidth_aadya\",\n",
    "        \"OT01V_framesPerSecond_ellen\",\n",
    "        \"OT01V_framesPerSecond_aadya\",\n",
    "\t\t\"OT01V_totalPacketSendDelay_ellen\",\n",
    "        \"OT01V_totalPacketSendDelay_aadya\",\n",
    "        \"OT01V_totalPacketSendDelay_packetsSent_in_ms_ellen\",\n",
    "        \"OT01V_totalPacketSendDelay_packetsSent_in_ms_aadya\",\n",
    "        \"RIV_roundTripTime_ellen\",\n",
    "        \"RIV_roundTripTime_aadya\",\n",
    "        \"RIV_fractionLost_ellen\",\n",
    "        \"RIV_fractionLost_aadya\",\n",
    "        \"RIA_fractionLost_ellen\",\n",
    "        \"RIA_fractionLost_aadya\",\n",
    "        \"RIA_roundTripTime_ellen\",\n",
    "        \"RIA_roundTripTime_aadya\",\n",
    "        \"ROA_roundTripTime_ellen\",\n",
    "        \"ROA_roundTripTime_aadya\",\n",
    "        \"AP_totalPlayoutDelay_ellen\",\n",
    "        \"AP_totalPlayoutDelay_aadya\"\n",
    "    ]\n",
    "\n",
    "with open(writeout_file_path, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for town in rural_town_names:\n",
    "        for location in range(1, 4):\n",
    "            readin_parent_file_path = f\"../parsed_CSVs/fieldwork/{town}/{town}{location}/test\"\n",
    "            for test in range(1, 5):\n",
    "                try:\n",
    "                    row = find_agg_stats_single_call(readin_parent_file_path, test)\n",
    "                    writer.writerow([f\"{town}{location}{test}\"] + row)\n",
    "                except Exception as E:\n",
    "                    if test != 4:\n",
    "                        print(f\"WARNING: unable to generate aggregate statistics for {town}{location}{test} due to...\")\n",
    "                        print(\"       \", E)\n",
    "    \n",
    "    for suburb in urban_suburb_names:\n",
    "        readin_parent_file_path = f\"../parsed_CSVs/fieldwork/{suburb}/test\"\n",
    "        for test in range(1, 4):\n",
    "            try:\n",
    "                row = find_agg_stats_single_call(readin_parent_file_path, test)\n",
    "                writer.writerow([f\"{suburb}{test}\"] + row)\n",
    "            except Exception as E:\n",
    "                print(f\"WARNING: unable to generate aggregate statistics for {suburb}{test}\")\n",
    "                print(\"       \", E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subjective_and_independent_vars_table(csv1_path, csv2_path, output_csv_path):\n",
    "    # Read both CSV files into pandas dataframes\n",
    "    df1 = pd.read_csv(csv1_path)\n",
    "    df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "    # Rename the first column to 'identifier' in both dataframes if not already named\n",
    "    df1.rename(columns={df1.columns[0]: 'identifier'}, inplace=True)\n",
    "    df2.rename(columns={df2.columns[0]: 'identifier'}, inplace=True)\n",
    "\n",
    "    # Merge the two dataframes on the 'identifier' column using an inner join\n",
    "    merged_df = pd.merge(df1, df2, on='identifier', how='inner')\n",
    "\n",
    "    # Write the merged dataframe to a new CSV file\n",
    "    merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "independent_vars_file_path = \"independent_vars_tables/fieldwork_independent_vars_table.csv\"\n",
    "subjective_file_path = \"../test_combos/fieldwork/fieldwork_subjective.csv\"\n",
    "writeout_file_path = \"regression_tables/fieldwork_regression_table.csv\"\n",
    "combine_subjective_and_independent_vars_table(independent_vars_file_path, subjective_file_path, writeout_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
